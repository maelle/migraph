---
title: "5. Equivalence"
author: "James Hollway"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{5. Equivalence}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Setting up

The data we're going to use here is included in the `{migraph}` package.
This dataset is multiplex, meaning that it contains 
several different types of ties: friendship, social and task interactions.

```{r setup}
library(migraph)
data("ison_algebra", package = "migraph")
# ?migraph::ison_algebra
```

Note that you do not need to load the package using `library()` to get the data.
Now you know how to create new matrices in R, load .csv files, 
saved .RData files, and data from packages!

## Naming anonymous networks

The network is anonymous, but I think it would be nice to add some names,
even if it's just pretend. 
Luckily, `{migraph}` has a function for this.
This makes plotting the network just a wee bit more accessible and interpretable:

```{r addingnames}
ison_algebra <- to_named(ison_algebra)
autographr(ison_algebra)
```

Note that you will likely get a different set of names,
as they are assigned randomly from a pool of (American) first names.

## Separating multiplex networks

As a multiplex network, 
there are actually three different types of tie in this network.
We can extract them and investigate them separately using `to_uniplex()`:

```{r separatingnets}
(friends <- to_uniplex(ison_algebra, "friend_tie"))
gfriend <- autographr(friends) + ggtitle("Friendship")
(social <- to_uniplex(ison_algebra, "social_tie"))
gsocial <- autographr(social) + ggtitle("Social")
(tasks <- to_uniplex(ison_algebra, "task_tie"))
gtask <- autographr(tasks) + ggtitle("Task")
gfriend + gsocial + gtask
```

Note also that these are weighted networks.
`autographr()` automatically registers these different weights and plots them.

# Structural Holes and Constraint

Where might innovation be most likely to occur in these networks?
Let's take a look at which actors are least constrained 
by their position in the task network to begin with.
`{migraph}` makes this easy enough with the `node_constraint()` function.

```{r constraint}
node_constraint(tasks)
```

We see that this function returns a vector of 
constraint scores that can range between 0 and 1.
Let's size the nodes according to this score,
and identify the node with the minimum constraint score.

```{r constraintplot}
autographr(tasks, highlight_measure = "node_constraint",
           identify_function = "min")
```

Why minimum? And what can we learn from this plot
about where innovation might occur within this network?

# Structural Equivalence

Now we are going to identify and interpret the roles
or relations between a set of structurally equivalent positions.
We're going to identify structurally equivalent positions
across all the data that we have, including 'task', 'social', and 'friend' ties,
but the unit test this week will ask you to run this on a uniplex version of this network.

## Finding structurally equivalent classes

In `{migraph}`, finding how the nodes of a network can be partitioned
into structurally equivalent classes is as easy as:

```{r find-se}
node_structural_equivalence(ison_algebra)
ison_algebra %>% 
  mutate(se = node_structural_equivalence(ison_algebra)) %>% 
  autographr(node_color = "se")
```

But actually, a lot is going on behind the scenes here that we can unpack.

## Step one: starting with a census

All equivalence classes are based on nodes' similarity across some profile of motifs.
In `{migraph}`, we call these motif censuses.
Any kind of census can be used, and `{migraph}` includes a few options,
but `node_structural_equivalence()` is based off of the census of all the nodes' ties,
both outgoing and incoming ties, to reveal their relationships to tie partners.

```{r construct-cor}
node_tie_census(ison_algebra)
dim(node_tie_census(ison_algebra))
```

We can see that the result is a matrix of `r dim(node_tie_census(ison_algebra))[1]` rows
and `r dim(node_tie_census(ison_algebra))[2]` columns, 
because we want to catalogue or take a census of all the different incoming/outgoing partners 
our 16 nodes might have across these three networks.
Note also that the result is a weighted matrix; 
what would you do if you wanted it to be binary?

Note that `node_tie_census()` does not need to be passed to `node_structural_equivalence()` ---
this is done automatically --- 
but the more generic `node_equivalence()` can be used with whichever tie census is desired.
Feel free to explore using some of the other censuses available in `{migraph}`,
though some common ones are already used in the other equivalence convenience functions,
`node_regular_equivalence()` and `node_automorphic_equivalence()`.

## Step two: growing a tree of similarity

The next part is all done internally,
though there are several important parameters that can be set to obtain different results.
Using the census as material, the distances in (dis)similarity between the nodes
is used to create a dendrogram of 

There are two main parameters that can be set here.
First, users can set the type of distance measure used.
This is passed on to `stats::dist()`, 
so that help page should be consulted for more details.
By default `"euclidean"` is used.

Second, we can also set the type of clustering algorithm employed.
By default, `{migraph}`'s equivalence functions use hierarchical clustering, `"hier"`,
but for compatibility and enthusiasts, we also offer `"concor"`,
which implements a CONCOR (CONvergence of CORrelations) algorithm.

We can see the difference from varying the clustering algorithm and/or distance
by plotting the dendrograms (hidden) in the output from `node_structural_equivalence()`:

```{r vary-clust}
plot(node_structural_equivalence(ison_algebra, cluster = "hier", distance = "euclidean"))
plot(node_structural_equivalence(ison_algebra, cluster = "hier", distance = "manhattan"))
plot(node_structural_equivalence(ison_algebra, cluster = "concor"))
```

So plotting a `membership` vector from `{migraph}` returns a dendrogram
with the names of the nodes on the _y_-axis and the distance between them on the _x_-axis.
Basically, as we move to the right, we're allowing for
more and more dissimilarity among those we cluster together.
A fork or branching point indicates the level of dissimilarity
at which those two or more nodes would be said to be equivalent.
Where two nodes' branches join/fork is the distance between them,
so more similar nodes' branches fork closer to the tree's canopy,
and less similar (groups of) nodes don't join until basically they form a trunk.

Note that with the results using the hierarchical clustering algorithm,
the distance directly affects the structure of the tree (and the results).

The CONCOR dendrogram is a bit different though.
Instead it represents how converging correlations repreatedly bifurcate 
the nodes into one of two partitions.
As such the 'distance' is really just the (inverse) number of steps
of bifurcations until nodes belong to the same class.

## Step three: identifying the number of clusters

Another bit of information represented in the dendrogram
is where the tree should be cut (the dashed red line) and
how the nodes are assigned to the branches (clusters) present at that cut-point.

But where does this red line come from?
Or, more technically, how do we identify the number of clusters
into which to assign nodes?

`{migraph}` includes several different ways of establishing `k`,
or the number of clusters.
Remember, the further to the right the red line is 
(the lower on the tree the cut point is)
the more dissimilar we're allowing nodes in the same cluster to be.
We could set this ourselves by just passing `k` an integer.

```{r k-discrete}
plot(node_structural_equivalence(ison_algebra, k = 2))
```

But we're really just guessing. Maybe 2 is not the best `k`?
To establish that, we need to iterate through a number of potential `k`,
and consider their fitness by some metric.
There are a couple of options here.

One is to consider, for each `k`, how correlated this partition 
is with the observed network.
When there is one cluster for each vertex in the network, cell values will be
identical to the observed correlation matrix, and when there is one cluster 
for the whole network, the values will all be equal to the average correlation 
across the observed matrix.
So the correlations in each by-cluster matrix are correlated with the observed 
correlation matrix to see how well each by-cluster matrix fits the data.

Of course, the perfect partition would then be 
where all nodes are in their own cluster,
which is hardly 'clustering' at all.
Also, increasing `k` will always improve the correlation.
But if one were to plot these correlations as a line graph,
then we might expect there to be a relatively rapid increase
in correlation as we move from, for example, 3 clusters to 4 clusters,
but a relatively small increase from, for example, 13 clusters to 14 clusters.
By identifying the inflection point in this line graph,
`{migraph}` selects a number of clusters that represents a trade-off
between fit and parsimony.
This is the `k = "elbow"` method.

The other option is to evaluate a candidate for `k` based
not on correlation but on a metric of 
how similar each node in a cluster is to others in its cluster
_and_ how dissimilar each node is to those in a neighbouring cluster.
When averaged over all nodes and all clusters, 
this provides a 'silhouette coefficient' for a candidate of `k`.
Choosing the number of clusters that maximizes this coefficient,
which is what `k = "silhouette"` does,
can return a somewhat different result to the elbow method.
See what we have here, with all other arguments held the same:

```{r elbowsil}
plot(node_structural_equivalence(ison_algebra, k = "elbow"))
plot(node_structural_equivalence(ison_algebra, k = "silhouette"))
```

Ok, so it looks like the elbow method returns `k == 3` as a good trade-off
between fit and parsimony.
The silhouette method, by contrast, sees `k == 4` as maximising cluster similarity
and dissimilarity.
Either is probably fine here, 
and there is much debate around how to select the number of clusters anyway,
but the silhouette method seems to do a better job of identifying how unique
`r node_names(ison_algebra)[16]` is.
The silhouette method is also the default in `{migraph}`.

Note that there is a somewhat hidden parameter here, `range`.
Since testing across all possible numbers of clusters can get 
computationally expensive (not to mention uninterpretable) for large networks,
`{migraph}` only considers up to 8 clusters by default.
This however can be modified to be higher or lower, e.g. `range = 16`.

Finally, one last option is `k = "strict"`,
which only assigns nodes to the same partition 
if there is a distance of zero between them.
This is quick and rigorous solution,
however oftentimes this misses the point in finding clusters of nodes that, 
despite some variation, can be considered as similar on some dimension.

```{r strict}
plot(node_structural_equivalence(ison_algebra, k = "strict"))
```

Here for example, no two nodes have precisely the same tie-profile,
otherwise their branches would join/fork at a distance of 0.
As such, `k = "strict"` partitions the network into 16 clusters.
Where networks have a number of nodes with strictly the same profiles,
such a k-selection method might be helpful to recognise those in exactly the same structural position,
but here it essentially just reports nodes' identity.

# Blockmodelling

Now we can use the 4-cluster solution to generate blockmodels.
We'll do this on the valued network, but binary is possible too.

```{r structblock, eval=FALSE}
(task_blockmodel <- blockmodel(m182_task, str_clu))
plot(task_blockmodel)
(social_blockmodel <- blockmodel(m182_social, str_clu))
plot(social_blockmodel)
(friend_blockmodel <- blockmodel(m182_friend, str_clu))
plot(friend_blockmodel)
```

What do these plots show?
Plotting the blockmodel like this is particularly useful for characterising what
the profile of ties (partners) is for each position/equivalence class.
We might characterise them like so:

```{html}
- `r names(str_clu[which(str_clu==1)])` work together only in reciprocal pairs on tasks, -->
<!-- preferring to approach `r names(str_clu[which(str_clu==4)])` but also those of the other two roles. -->
While they hang out with each other socially quite a bit, friendship from groups 2 and 3 are preferred.
We shall call them *freaks*.
<!-- - `r names(str_clu[which(str_clu==2)])` also work together only in reciprocal pairs, -->
<!-- preferring to work collaboratively with group 1 or also `r names(str_clu[which(str_clu==4)])`. -->
They also tend to count those from group 1 as friends,
and hang out with everyone else but themselves.
We shall call them *squares*.
<!-- - `r names(str_clu[which(str_clu==3)])` will work with either some in group 1 and 3, or 2, -->
<!-- but again prefer `r names(str_clu[which(str_clu==4)])` for task advice. -->
They are pretty good friends with each other though,
and pretty happy to socialise with everyone.
We shall call them *nerds*.
<!-- - `r names(str_clu[which(str_clu==4)])` is a loner, no friends,  -->
but everyone hangs out with them for task advice, therefore the *geek*.
```

## Reduced graph

Finally, we can reduce the graph to just interactions between roles.
Let's start off by graphing the valued/weighted blockmodel.

```{r strredgraph, eval=FALSE}
group_labels <- c("Freaks","Squares","Nerds","Geek")
(social_reduced <- reduce_graph(social_blockmodel, group_labels))
autographr(social_reduced)
(task_reduced <- reduce_graph(task_blockmodel, group_labels))
autographr(task_reduced)
(friend_reduced <- reduce_graph(friend_blockmodel, group_labels))
autographr(friend_reduced)
```

What can help interpreting these profiles is getting the summaries of average weight ties by group.

```{r str-group, eval=FALSE}
summary(m182_task, str_clu)
```

```
# ADVANCED: Note on deductive clustering:

# It's pretty straightforward to alter the code above to test hypotheses.
# Simply supply your own cluster vector, where the elements in the vector are in 
# the same order as the vertices in the matrix, and the values represent the
# cluster to which each vertex belongs. 

  task_social_cors <- cor(task_social)
  
# For example, if you believed that actors 2, 7, and 8 formed one group, 
# actor 16 former another group, and everyone else formed a third group, 
# you could represent this as follows:
dedclust = c(1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 3)

# Then examine the fitness of this cluster configuration as follows:
dedclust_mat <- NetCluster::generate_cluster_cor_mat(task_social_cors, dedclust)
dedclust_mat
gcor(dedclust_mat, task_social_cors)
```

```
# ADVANCED: Note that we can also blockmodel our communities from last time.
# walktrap_blockmodel <- blockmodel(get.adjacency(m182_main, sparse = F), 
#                                   friend_wt$membership)
# plot(walktrap_blockmodel)
# walktrap_blockmodel
# # And graphs that from the reduced form blockmodels...
# walktrap_blockmodel_red <- graph.adjacency(walktrap_blockmodel$block.model, weighted = T)
# plot(walktrap_blockmodel_red, edge.width = E(walktrap_blockmodel_red)$weight,
#      vertex.color = rainbow(2) )
# # Admittedly, not terribly interesting...
# 
# edgebet_blockmodel <- blockmodel(get.adjacency(m182_main, sparse = F), 
#                                  friend_eb$membership)
# plot(edgebet_blockmodel) # blockmodel
# edgebet_blockmodel_red <- graph.adjacency(edgebet_blockmodel$block.model, weighted = T)
# plot(edgebet_blockmodel_red, edge.width=E(edgebet_blockmodel_red)$weight,
#      vertex.color=rainbow(3) ) # reduced graph
# # Cool
# 
# fastgreed_blockmodel <- blockmodel(get.adjacency(m182_main, sparse = F), 
#                                    friend_fg$membership)
# plot(fastgreed_blockmodel) # blockmodel
# fastgreed_blockmodel_red <- graph.adjacency(fastgreed_blockmodel$block.model, weighted = T)
# plot(fastgreed_blockmodel_red, edge.width=E(fastgreed_blockmodel_red)$weight,
#      vertex.color=rainbow(3) ) # reduced graph
```

# Unit Test

1. Visualise the m182 FRIENDSHIP network, 
sizing the vertices by constraint and identifying the structural hole
What would being in a structural hole mean here?
2. Plot labelled, reduced graph of REGULARLY equivalent classes on friendship network only
3. Plot labelled, reduced graph of STRUCTURALLY equivalent classes on task network only
